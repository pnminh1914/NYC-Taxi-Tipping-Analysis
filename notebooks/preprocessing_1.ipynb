{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['JAVA_HOME'] = '/opt/homebrew/Cellar/openjdk/22.0.2/libexec/openjdk.jdk/Contents/Home'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/16 17:04:06 WARN Utils: Your hostname, Phams-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 172.16.47.168 instead (on interface en0)\n",
      "24/08/16 17:04:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/08/16 17:04:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Initialize spark session\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 1 raw data transformation\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"8g\") \n",
    "    .config(\"spark.executor.memory\", \"8g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging monthly parquet files into 1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all monthly records into one dataframe\n",
    "sdf_yellow = spark.read.parquet('../data/landing/2023-01.parquet')\n",
    "\n",
    "for month in range(2, 13):\n",
    "    month = str(month).zfill(2)\n",
    "    df_next = spark.read.parquet(f'../data/landing/2023-{month}.parquet')\n",
    "    sdf_yellow = sdf_yellow.union(df_next)\n",
    "    \n",
    "original_count = sdf_yellow.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpep_pickup_datetime:\n",
      "\tMax: 2024-01-03 19:42:57 \n",
      "\tMin: 2001-01-01 00:06:49\n",
      "\n",
      "tpep_dropoff_datetime:\n",
      "\tMax: 2024-01-03 20:15:55 \n",
      "\tMin: 1970-01-20 10:16:32 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/16 17:04:13 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------\n",
      " summary               | count                \n",
      " passenger_count       | 37000870             \n",
      " trip_distance         | 38310226             \n",
      " trip_duration_minutes | 38310226             \n",
      " fare_amount           | 38310226             \n",
      " extra                 | 38310226             \n",
      " mta_tax               | 38310226             \n",
      " tip_amount            | 38310226             \n",
      " tolls_amount          | 38310226             \n",
      " improvement_surcharge | 38310226             \n",
      " total_amount          | 38310226             \n",
      " congestion_surcharge  | 37000870             \n",
      "-RECORD 1-------------------------------------\n",
      " summary               | mean                 \n",
      " passenger_count       | 1.3704258575541601   \n",
      " trip_distance         | 4.088946216083186    \n",
      " trip_duration_minutes | 16.716849137965173   \n",
      " fare_amount           | 19.522250636423735   \n",
      " extra                 | 1.5560566439884764   \n",
      " mta_tax               | 0.4856166729478451   \n",
      " tip_amount            | 3.522265402976885    \n",
      " tolls_amount          | 0.5897361378145205   \n",
      " improvement_surcharge | 0.9794487273449829   \n",
      " total_amount          | 28.46194151631534    \n",
      " congestion_surcharge  | 2.264610487537185    \n",
      "-RECORD 2-------------------------------------\n",
      " summary               | stddev               \n",
      " passenger_count       | 0.8925924372139338   \n",
      " trip_distance         | 241.25089989010328   \n",
      " trip_duration_minutes | 4564.075418389051    \n",
      " fare_amount           | 75.72728960021986    \n",
      " extra                 | 2.450398738630977    \n",
      " mta_tax               | 0.10956288620186586  \n",
      " tip_amount            | 4.147060116226964    \n",
      " tolls_amount          | 2.2009994548076453   \n",
      " improvement_surcharge | 0.19914621328624868  \n",
      " total_amount          | 77.12820916916166    \n",
      " congestion_surcharge  | 0.7971480634151978   \n",
      "-RECORD 3-------------------------------------\n",
      " summary               | min                  \n",
      " passenger_count       | 0.0                  \n",
      " trip_distance         | 0.0                  \n",
      " trip_duration_minutes | -2.82482984666666... \n",
      " fare_amount           | -1087.3              \n",
      " extra                 | -39.17               \n",
      " mta_tax               | -0.5                 \n",
      " tip_amount            | -411.0               \n",
      " tolls_amount          | -91.3                \n",
      " improvement_surcharge | -1.0                 \n",
      " total_amount          | -1094.05             \n",
      " congestion_surcharge  | -2.5                 \n",
      "-RECORD 4-------------------------------------\n",
      " summary               | max                  \n",
      " passenger_count       | 9.0                  \n",
      " trip_distance         | 345729.44            \n",
      " trip_duration_minutes | 10029.183333333332   \n",
      " fare_amount           | 386983.63            \n",
      " extra                 | 10002.5              \n",
      " mta_tax               | 53.16                \n",
      " tip_amount            | 4174.0               \n",
      " tolls_amount          | 665.56               \n",
      " improvement_surcharge | 1.0                  \n",
      " total_amount          | 386987.63            \n",
      " congestion_surcharge  | 2.75                 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add new columns from existing columns\n",
    "sdf_yellow = sdf_yellow.withColumn('trip_duration_minutes',\n",
    "                   (F.unix_timestamp('tpep_dropoff_datetime').cast('long') - \n",
    "                    F.unix_timestamp('tpep_pickup_datetime').cast('long')) / 60)\n",
    "\n",
    "sdf_yellow = sdf_yellow.withColumn('pickup_date', F.to_date(sdf_yellow['tpep_pickup_datetime']))\n",
    "sdf_yellow = sdf_yellow.withColumn('pickup_hour', F.hour(sdf_yellow['tpep_pickup_datetime']))\n",
    "\n",
    "sdf_yellow = sdf_yellow.withColumn('dropoff_date', F.to_date(sdf_yellow['tpep_dropoff_datetime']))\n",
    "\n",
    "# Check earliest and latest of datetime variables\n",
    "print(\"tpep_pickup_datetime:\\n\\tMax:\", sdf_yellow.agg({\"tpep_pickup_datetime\": \"max\"}).collect()[0][0],\n",
    "     \"\\n\\tMin:\", sdf_yellow.agg({\"tpep_pickup_datetime\": \"min\"}).collect()[0][0])\n",
    "\n",
    "print(\"\\ntpep_dropoff_datetime:\\n\\tMax:\", sdf_yellow.agg({\"tpep_dropoff_datetime\": \"max\"}).collect()[0][0],\n",
    "     \"\\n\\tMin:\", sdf_yellow.agg({\"tpep_dropoff_datetime\": \"min\"}).collect()[0][0], '\\n')\n",
    "\n",
    "# Check other variables\n",
    "sdf_yellow.select(['passenger_count',\n",
    "           'trip_distance',\n",
    "           'trip_duration_minutes',\n",
    "           'fare_amount',\n",
    "           'extra',\n",
    "           'mta_tax',\n",
    "           'tip_amount',\n",
    "           'tolls_amount',\n",
    "           'improvement_surcharge',\n",
    "           'total_amount',\n",
    "           'congestion_surcharge']).describe().show(vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering for invalid trips according to preprocessing specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_trips_only_yellow = sdf_yellow.filter(F.col('passenger_count') > 0) \\\n",
    "                                    .filter(F.col('trip_distance') >= 0.5) \\\n",
    "                                    .filter(F.col('trip_duration_minutes') >= 1) \\\n",
    "                                    .filter(F.col('fare_amount') >= 2.5) \\\n",
    "                                    .filter(F.col('extra') >= 0) \\\n",
    "                                    .filter(F.col('mta_tax') >= 0) \\\n",
    "                                    .filter(F.col('tip_amount') >= 0) \\\n",
    "                                    .filter(F.col('tolls_amount') >= 0) \\\n",
    "                                    .filter(F.col('improvement_surcharge') >= 0) \\\n",
    "                                    .filter(F.col('total_amount') >= 2.5) \\\n",
    "                                    .filter((F.col('pickup_date') >= '2023-01-01') & (F.col('pickup_date') <= '2023-12-31')) \\\n",
    "                                    .filter((F.col('dropoff_date') >= '2023-01-01') & (F.col('dropoff_date') <= '2023-12-31'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling outliers and capping trip duration at 5 hours (300 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/16 17:04:23 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "valid_trips_only_yellow = valid_trips_only_yellow.where((F.col('fare_amount') <= valid_trips_only_yellow.selectExpr('percentile(fare_amount, 0.9999)').collect()[0][0]) &\n",
    "                (F.col('trip_distance') <= valid_trips_only_yellow.selectExpr('percentile(trip_distance, 0.9999)').collect()[0][0]) &\n",
    "                (F.col('tip_amount') <= valid_trips_only_yellow.selectExpr('percentile(tip_amount, 0.9999)').collect()[0][0]) &\n",
    "                (F.col('total_amount') <= valid_trips_only_yellow.selectExpr('percentile(total_amount, 0.9999)').collect()[0][0]) &\n",
    "                (F.col('tolls_amount') <= valid_trips_only_yellow.selectExpr('percentile(tolls_amount, 0.9999)').collect()[0][0]) &\n",
    "                (F.col('trip_duration_minutes') <= 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After filtering for valid trips only and handling outliers, approximately 11% of the original records were removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:===================================================>    (89 + 7) / 96]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries deleted: 4047740\n",
      "Proportion of data kept: 0.89434309262493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "processed_count = valid_trips_only_yellow.count()\n",
    "print(\"Number of entries deleted: \" + str(original_count - processed_count))\n",
    "print(\"Proportion of data kept: \" + str(processed_count/original_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing data into `data/raw` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '../data/raw/'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "valid_trips_only_yellow.write.mode('overwrite').parquet(f'{output_dir}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('3.10.4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6857171c288a27f4076b69feee1624abed3d2b82ff763169396fbbf8c8e33653"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
